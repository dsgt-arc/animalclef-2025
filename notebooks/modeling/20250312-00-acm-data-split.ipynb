{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting for Open-Set Re-Identification: A Comprehensive Guide\n",
    "\n",
    "This notebook documents the crucial data splitting strategy employed for evaluating an open-set re-identification (re-ID) model, specifically designed for wildlife datasets.  The goal is to accurately assess the model's ability to both re-identify *known* individuals (those seen during training) and to recognize *new, unseen* individuals â€“ a challenging but realistic scenario in wildlife monitoring.\n",
    "\n",
    "### I. The Challenge: Open-Set vs. Closed-Set Re-ID\n",
    "\n",
    "Traditional (closed-set) re-ID assumes that all individuals appearing in the test set are also present in the training set (though with different images).  Open-set re-ID relaxes this assumption.  In an open-set setting, the model must:\n",
    "\n",
    "1.  **Re-identify Known Individuals:**  Correctly match new images of individuals that were seen during training.\n",
    "2.  **Recognize Unknown Individuals:**  Identify images of individuals *not* seen during training as belonging to a *new* individual (not one of the known ones).\n",
    "\n",
    "This is significantly harder than closed-set re-ID.  A model that simply memorizes training images would fail completely on the open-set task.\n",
    "\n",
    "### II. Key Concepts and Metrics\n",
    "\n",
    "*   **BAKS (Balanced Accuracy on Known Samples):**  Measures the accuracy of the model in re-identifying individuals that were present in the training data.  It's \"balanced\" because it considers the accuracy for each individual separately and then averages, preventing bias towards individuals with many images.\n",
    "\n",
    "*   **BAUS (Balanced Accuracy on Unknown Samples):** Measures the accuracy of the model in correctly identifying images of individuals *not* present in the training data as belonging to \"unknown\" individuals. This is the core metric for open-set performance.\n",
    "\n",
    "*   **Geometric Mean:** The final performance metric is the geometric mean of BAKS and BAUS: `sqrt(BAKS * BAUS)`.  This is used instead of the arithmetic mean to penalize models that perform well on only one of the tasks (e.g., a model that always predicts \"unknown\" would have 100% BAUS but 0% BAKS, leading to a 0% geometric mean).\n",
    "\n",
    "*    **Individuals vs. Images:** It's *crucial* to distinguish between individuals (unique animals) and images (photos of those animals). The split is performed at the *individual* level, but evaluation considers both individual-level and image-level correctness.\n",
    "\n",
    "### III. The Splitting Strategy: Ensuring a Valid and Unbiased Evaluation\n",
    "\n",
    "To properly evaluate both BAKS and BAUS, we need a specific data splitting strategy. A simple random split of images is insufficient because it would likely lead to images of the *same* individual appearing in both the training and test sets, creating data leakage and artificially inflating performance.\n",
    "\n",
    "**The Core Principles:**\n",
    "\n",
    "1.  **Individual-Based Splitting:** The data is split into three sets (Training, Validation, and Test) primarily based on individual IDs. All images of unknown individuals are assigned to the same split (either Validation or Test, but never Train). For known individuals (those present in the Training set), their images are further split across the Training, Validation, and Test sets, ensuring that no single image appears in more than one set. This prevents data leakage and allows for a valid evaluation of both BAKS and BAUS.\n",
    "\n",
    "2.  **Known and Unknown Subsets:** The Validation and Test sets each contain two subsets of individuals:\n",
    "    *   **Known Individuals:**  Individuals that are *also* present in the Training set. These are used to evaluate BAKS.\n",
    "    *   **Unknown Individuals:** Individuals that are *completely distinct* from those in the Training set.  These are used to evaluate BAUS.\n",
    "\n",
    "3.  **Image-Level Separation (Within Known Individuals):** Even for the \"known\" individuals that appear in multiple sets, the *specific images* of those individuals must be different across the Train, Validation, and Test sets. This prevents the model from overfitting to specific images and ensures a realistic evaluation.\n",
    "\n",
    "**The Splitting Process (High-Level):**\n",
    "\n",
    "1. **Initial Split:** First divide all of our unique individual IDs into two disjoint sets: *train*, and *temp_test*.\n",
    "2. **Further split** the set *temp_test* into two disjoint sets *val_unknown* and *test_unknown*.\n",
    "3.  **Image Split (Known Individuals):**\n",
    "    * Iterate over the set of unique train individual IDs.\n",
    "    * Get all of the images that the individual appears in.\n",
    "    * Split the images up into those that will be in the training set, those that will be in the validation set, and those that will be in the test set.\n",
    "\n",
    "**Detailed Breakdown and Code Implementation**\n",
    "This part is done by using the `split_reid_data` function.\n",
    "\n",
    "**IV. Data Split Summary**\n",
    "\n",
    "The resulting split has the following structure:\n",
    "| Split       | Num Individuals | Num Images | Known Individuals | Unknown Individuals | Purpose                                                                                                                                                             |\n",
    "|-------------|-----------------|------------|-------------------|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Train       | 404             | 3392         |      404             |      0                | Used to train the re-identification model to distinguish between the known individuals.                                                                                |\n",
    "| Validation  |      458           |  2575          |        404           |      54                | Used for hyperparameter tuning and model selection. BAKS is calculated on the known individuals, BAUS on the unknown individuals.                                          |\n",
    "| Test        |      620         |       6568     |    404               |      216          | Used for *final, unbiased* performance evaluation. BAKS is calculated on the known individuals, BAUS on the unknown individuals. This reflects real-world performance. |\n",
    "\n",
    "\n",
    "**V. Key Considerations and Potential Issues**\n",
    "\n",
    "*   **Image Count Filtering:**  Individuals with very few images (e.g., only one or two) can negatively impact model training and evaluation. We filter out these individuals *after* the initial individual-level split, but *before* the image-level split within the known individuals.\n",
    "*   **Data Augmentation:** Data augmentation techniques (e.g., rotations, flips, color adjustments) can be used to increase the effective size of the training set.  However, augmentation must be applied *carefully* to avoid introducing artificial correlations that could lead to data leakage.  Augmentation should be applied *after* the train/validation/test split.\n",
    "* **No Overlap of Images**: there is no overlap of image ids between any split.\n",
    "\n",
    "By adhering to this rigorous splitting strategy, we ensure a valid, unbiased, and informative evaluation of our open-set re-ID model, providing a realistic assessment of its performance in a challenging wildlife monitoring context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/13 02:14:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/13 02:14:35 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://atl1-1-02-003-16-2.pace.gatech.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>clef</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffb9bf5060>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image_id: integer (nullable = true)\n",
      " |-- identity: string (nullable = true)\n",
      " |-- path: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- orientation: string (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      " |-- split: string (nullable = true)\n",
      " |-- dataset: string (nullable = true)\n",
      " |-- token: struct (nullable = true)\n",
      " |    |-- cls: array (nullable = true)\n",
      " |    |    |-- element: float (containsNull = true)\n",
      " |    |-- avg_patch: array (nullable = true)\n",
      " |    |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from animalclef.spark import get_spark\n",
    "from pyspark.sql import functions as F, Window\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = get_spark(cores=4, memory=\"10g\")\n",
    "display(spark)\n",
    "\n",
    "metadata = spark.read.parquet(f\"{Path.home()}/shared/animalclef/data/parquet/metadata\")\n",
    "embeddings = spark.read.parquet(\n",
    "    f\"{Path.home()}/shared/animalclef/data/embeddings/dinov2\"\n",
    ")\n",
    "df = metadata.join(embeddings, on=\"image_id\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+\n",
      "|summary|            identity|             count|\n",
      "+-------+--------------------+------------------+\n",
      "|  count|                1102|              1103|\n",
      "|   mean|                NULL|13.788757932910245|\n",
      "| stddev|                NULL| 68.53376094252918|\n",
      "|    min|  LynxID2025_lynx_00|                 1|\n",
      "|    max|SeaTurtleID2022_t610|              2135|\n",
      "+-------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(df.select(\"identity\").distinct().count())\n",
    "df.groupBy(\"identity\").count().describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|freq|count|\n",
      "+----+-----+\n",
      "|   1|  317|\n",
      "|   2|  111|\n",
      "|   3|   79|\n",
      "|   4|   58|\n",
      "|   5|   66|\n",
      "|   6|   44|\n",
      "|   7|   39|\n",
      "|   8|   32|\n",
      "|   9|   33|\n",
      "|  10|   17|\n",
      "|  11|   18|\n",
      "|  12|   13|\n",
      "|  13|   19|\n",
      "|  14|   13|\n",
      "|  15|   16|\n",
      "|  16|   12|\n",
      "|  17|    9|\n",
      "|  18|   15|\n",
      "|  19|   12|\n",
      "|  20|   10|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = (\n",
    "    df.where(\"identity is not null\")\n",
    "    .groupBy(\"identity\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"freq\")\n",
    ").cache()\n",
    "counts.groupBy(\"freq\").count().orderBy(\"freq\").show()\n",
    "\n",
    "plt.hist(counts.toPandas().freq, bins=50, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cls</th>\n",
       "      <th>avg_patch</th>\n",
       "      <th>identity_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3414</td>\n",
       "      <td>LynxID2025_lynx_04</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[1.953707, -0.06146222, -1.966017, -0.31764427...</td>\n",
       "      <td>[0.47695184, -0.74326456, -0.82782966, -0.7631...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>LynxID2025_lynx_04</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[1.3321328, -2.366122, -3.25668, 0.5420925, 0....</td>\n",
       "      <td>[0.6709354, -0.65619326, -0.81696904, -0.69181...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329</td>\n",
       "      <td>LynxID2025_lynx_04</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[2.5965683, -0.9103739, -1.8469927, -1.1413739...</td>\n",
       "      <td>[1.1247859, -0.4730551, -0.87914395, -1.143541...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2264</td>\n",
       "      <td>LynxID2025_lynx_08</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[1.7082918, -2.1121547, -1.5560057, -0.0668072...</td>\n",
       "      <td>[1.064861, -1.0406678, -0.5095228, -0.78655636...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717</td>\n",
       "      <td>LynxID2025_lynx_16</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[2.0524616, -3.7293742, 0.29863188, 2.1957643,...</td>\n",
       "      <td>[0.89284337, -1.0155127, -0.25687754, -0.20243...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id            identity     dataset  \\\n",
       "0      3414  LynxID2025_lynx_04  LynxID2025   \n",
       "1       472  LynxID2025_lynx_04  LynxID2025   \n",
       "2       329  LynxID2025_lynx_04  LynxID2025   \n",
       "3      2264  LynxID2025_lynx_08  LynxID2025   \n",
       "4       717  LynxID2025_lynx_16  LynxID2025   \n",
       "\n",
       "                                                 cls  \\\n",
       "0  [1.953707, -0.06146222, -1.966017, -0.31764427...   \n",
       "1  [1.3321328, -2.366122, -3.25668, 0.5420925, 0....   \n",
       "2  [2.5965683, -0.9103739, -1.8469927, -1.1413739...   \n",
       "3  [1.7082918, -2.1121547, -1.5560057, -0.0668072...   \n",
       "4  [2.0524616, -3.7293742, 0.29863188, 2.1957643,...   \n",
       "\n",
       "                                           avg_patch  identity_count  \n",
       "0  [0.47695184, -0.74326456, -0.82782966, -0.7631...               3  \n",
       "1  [0.6709354, -0.65619326, -0.81696904, -0.69181...               3  \n",
       "2  [1.1247859, -0.4730551, -0.87914395, -1.143541...               3  \n",
       "3  [1.064861, -1.0406678, -0.5095228, -0.78655636...               1  \n",
       "4  [0.89284337, -1.0155127, -0.25687754, -0.20243...              36  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new column for identity count\n",
    "pdf = df.select(\n",
    "    \"image_id\",\n",
    "    \"identity\",\n",
    "    \"dataset\",\n",
    "    \"token.*\",\n",
    "    F.count(\"image_id\").over(Window.partitionBy(\"identity\")).alias(\"identity_count\"),\n",
    ").toPandas()\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cls</th>\n",
       "      <th>avg_patch</th>\n",
       "      <th>identity_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3113</td>\n",
       "      <td>LynxID2025_lynx_16</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[-1.2353026, -0.20536101, 0.61724025, 1.355893...</td>\n",
       "      <td>[0.23009793, -0.599779, 0.09589866, -1.018367,...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2766</td>\n",
       "      <td>LynxID2025_lynx_16</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[1.1601936, -0.30430153, -3.4015892, 0.7278578...</td>\n",
       "      <td>[1.0587692, 0.15164235, -0.14883831, -1.105805...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1092</td>\n",
       "      <td>LynxID2025_lynx_16</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[1.6077322, -2.6395178, -2.5117278, 1.3201498,...</td>\n",
       "      <td>[0.94769865, -0.7683547, 0.045931105, -0.43619...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2863</td>\n",
       "      <td>LynxID2025_lynx_16</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[2.9512155, -1.2826347, -0.9431905, -0.3966249...</td>\n",
       "      <td>[0.987959, -0.4492482, -0.5739524, -1.4712, 1....</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3546</td>\n",
       "      <td>LynxID2025_lynx_16</td>\n",
       "      <td>LynxID2025</td>\n",
       "      <td>[4.8651624, -3.594092, 0.5640984, 0.20187731, ...</td>\n",
       "      <td>[0.94039714, -0.7215976, -0.038915355, 0.04608...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id            identity     dataset  \\\n",
       "7       3113  LynxID2025_lynx_16  LynxID2025   \n",
       "8       2766  LynxID2025_lynx_16  LynxID2025   \n",
       "10      1092  LynxID2025_lynx_16  LynxID2025   \n",
       "11      2863  LynxID2025_lynx_16  LynxID2025   \n",
       "14      3546  LynxID2025_lynx_16  LynxID2025   \n",
       "\n",
       "                                                  cls  \\\n",
       "7   [-1.2353026, -0.20536101, 0.61724025, 1.355893...   \n",
       "8   [1.1601936, -0.30430153, -3.4015892, 0.7278578...   \n",
       "10  [1.6077322, -2.6395178, -2.5117278, 1.3201498,...   \n",
       "11  [2.9512155, -1.2826347, -0.9431905, -0.3966249...   \n",
       "14  [4.8651624, -3.594092, 0.5640984, 0.20187731, ...   \n",
       "\n",
       "                                            avg_patch  identity_count  \n",
       "7   [0.23009793, -0.599779, 0.09589866, -1.018367,...              36  \n",
       "8   [1.0587692, 0.15164235, -0.14883831, -1.105805...              36  \n",
       "10  [0.94769865, -0.7683547, 0.045931105, -0.43619...              36  \n",
       "11  [0.987959, -0.4492482, -0.5739524, -1.4712, 1....              36  \n",
       "14  [0.94039714, -0.7215976, -0.038915355, 0.04608...              36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Num Individuals</th>\n",
       "      <th>Num Images</th>\n",
       "      <th>Train Image Overlap</th>\n",
       "      <th>Val Image Overlap</th>\n",
       "      <th>Test Image Overlap</th>\n",
       "      <th>Train Image %</th>\n",
       "      <th>Val Image %</th>\n",
       "      <th>Test Image %</th>\n",
       "      <th>Known Individuals</th>\n",
       "      <th>Unknown Individuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>404</td>\n",
       "      <td>3392</td>\n",
       "      <td>3392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>458</td>\n",
       "      <td>2575</td>\n",
       "      <td>0</td>\n",
       "      <td>2575</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>404</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>620</td>\n",
       "      <td>6568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>404</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Split  Num Individuals  Num Images  Train Image Overlap  \\\n",
       "0       Train              404        3392                 3392   \n",
       "1  Validation              458        2575                    0   \n",
       "2        Test              620        6568                    0   \n",
       "\n",
       "   Val Image Overlap  Test Image Overlap  Train Image %  Val Image %  \\\n",
       "0                  0                   0          100.0          0.0   \n",
       "1               2575                   0            0.0        100.0   \n",
       "2                  0                6568            0.0          0.0   \n",
       "\n",
       "   Test Image %  Known Individuals  Unknown Individuals  \n",
       "0           0.0                404                    0  \n",
       "1           0.0                404                   54  \n",
       "2         100.0                404                  216  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_reid_data(\n",
    "    df: pd.DataFrame,\n",
    "    train_ratio: float = 0.6,\n",
    "    val_ratio: float = 0.2,\n",
    "    known_ratio: float = 0.5,  # Ratio of *images* of known indivs for val/test\n",
    "    group_col: str = \"identity\",\n",
    "    image_col: str = \"image_id\",\n",
    "    seed: int = 42,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    # 1. Split into Train and (Temp) Test sets based on individuals (groups)\n",
    "    unique_ids = df[group_col].unique()\n",
    "    train_ids, temp_test_ids = train_test_split(\n",
    "        unique_ids, train_size=train_ratio, random_state=seed\n",
    "    )\n",
    "\n",
    "    # 2. Split (Temp) Test into Validation and Final Test sets (unknown individuals).\n",
    "    val_unknown_ids, test_unknown_ids = train_test_split(\n",
    "        temp_test_ids, train_size=val_ratio, random_state=seed + 1\n",
    "    )\n",
    "    # 3. Split *images* of known individuals.\n",
    "    val_known_images = []\n",
    "    test_known_images = []\n",
    "    train_images = []\n",
    "    for indiv_id in sorted(train_ids):\n",
    "        images = df[df[group_col] == indiv_id][image_col].tolist()\n",
    "        if len(images) > 1:  # Only split if more than 1 image\n",
    "            known, unknown = train_test_split(\n",
    "                images, test_size=1 - known_ratio, random_state=seed + 2\n",
    "            )\n",
    "            val_known, test_known = train_test_split(\n",
    "                unknown, test_size=0.5, random_state=seed + 3\n",
    "            )\n",
    "\n",
    "            val_known_images.extend(val_known)\n",
    "            test_known_images.extend(test_known)\n",
    "            train_images.extend(known)\n",
    "        else:  # If only 1 image, put it in the validation set (or test, doesn't matter much)\n",
    "            val_known_images.extend(images)\n",
    "\n",
    "    # Create the known and unknown dfs\n",
    "    val_df_known = df[df[image_col].isin(val_known_images)]\n",
    "    test_df_known = df[df[image_col].isin(test_known_images)]\n",
    "    train_df = df[df[image_col].isin(train_images)]\n",
    "    val_df_unknown = df[df[group_col].isin(val_unknown_ids)]\n",
    "    test_df_unknown = df[df[group_col].isin(test_unknown_ids)]\n",
    "\n",
    "    # 4. Combine to create final DataFrames\n",
    "    val_df = pd.concat([val_df_known, val_df_unknown])\n",
    "    test_df = pd.concat([test_df_known, test_df_unknown])\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def summarize_split(train_df, val_df, test_df, id_col=\"identity\", image_col=\"image_id\"):\n",
    "    summary = pd.DataFrame(\n",
    "        {\n",
    "            \"Split\": [\"Train\", \"Validation\", \"Test\"],\n",
    "            \"Num Individuals\": [\n",
    "                train_df[id_col].nunique(),\n",
    "                val_df[id_col].nunique(),\n",
    "                test_df[id_col].nunique(),\n",
    "            ],\n",
    "            \"Num Images\": [len(train_df), len(val_df), len(test_df)],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    train_ids = set(train_df[id_col])\n",
    "    val_ids = set(val_df[id_col])\n",
    "    test_ids = set(test_df[id_col])\n",
    "\n",
    "    # Image overlaps (using set operations on image IDs)\n",
    "    train_images = set(train_df[image_col])\n",
    "    val_images = set(val_df[image_col])\n",
    "    test_images = set(test_df[image_col])\n",
    "\n",
    "    summary[\"Train Image Overlap\"] = [\n",
    "        len(train_images.intersection(train_images)),\n",
    "        len(train_images.intersection(val_images)),\n",
    "        len(train_images.intersection(test_images)),\n",
    "    ]\n",
    "    summary[\"Val Image Overlap\"] = [\n",
    "        len(val_images.intersection(train_images)),\n",
    "        len(val_images.intersection(val_images)),\n",
    "        len(val_images.intersection(test_images)),\n",
    "    ]\n",
    "    summary[\"Test Image Overlap\"] = [\n",
    "        len(test_images.intersection(train_images)),\n",
    "        len(test_images.intersection(val_images)),\n",
    "        len(test_images.intersection(test_images)),\n",
    "    ]\n",
    "\n",
    "    # now get the percentages of each of these\n",
    "    summary[\"Train Image %\"] = (\n",
    "        summary[\"Train Image Overlap\"] / len(train_images) * 100\n",
    "    ).round(2)\n",
    "    summary[\"Val Image %\"] = (\n",
    "        summary[\"Val Image Overlap\"] / len(val_images) * 100\n",
    "    ).round(2)\n",
    "    summary[\"Test Image %\"] = (\n",
    "        summary[\"Test Image Overlap\"] / len(test_images) * 100\n",
    "    ).round(2)\n",
    "\n",
    "    # Add Known/Unknown Counts to Summary (NEW)\n",
    "    summary[\"Known Individuals\"] = [\n",
    "        len(train_ids),\n",
    "        len(val_ids.intersection(train_ids)),\n",
    "        len(test_ids.intersection(train_ids)),\n",
    "    ]\n",
    "    summary[\"Unknown Individuals\"] = [\n",
    "        0,  # No unknowns in training\n",
    "        len(val_ids - train_ids),\n",
    "        len(test_ids - train_ids),\n",
    "    ]\n",
    "    return summary\n",
    "\n",
    "\n",
    "cond = (~pdf.identity.isnull()) & (pdf.identity_count > 2)\n",
    "train_df, val_df, test_df = split_reid_data(pdf[cond])\n",
    "summary_table = summarize_split(train_df, val_df, test_df)\n",
    "summary_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
